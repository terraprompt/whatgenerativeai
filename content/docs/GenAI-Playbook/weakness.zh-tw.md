---
title: "限制"
date: "2024-08-27"
author: "AI策略團隊"
tags: ["生成式AI", "AI限制", "技術策略", "AI實施"]
categories: ["技術", "AI策略"]
description: "探索生成式AI的限制，並了解哪些使用案例更適合傳統方法，從而在AI採用方面做出更明智的決策。"
slug: "了解限制-生成式ai的不足之處"
weight: 12
---

![導航AI的限制](/12.png)

# 生成式AI不足的使用案例
**導航AI的限制**

雖然生成式AI（GenAI）在各個領域都展現出了卓越的能力，但對組織來說，了解其限制至關重要。認識到生成式AI的不足之處不僅可以防止資源的錯誤分配，還可以確保在適當的情況下考慮其他可能更有效的解決方案。本節探討了當前生成式AI技術可能不是最佳選擇的特定使用案例和情境。

## 1. 高風險決策

儘管生成式AI模型非常複雜，但它們缺乏真正的理解能力，可能會產生自信但不正確的信息（這種現象被稱為"幻覺"）。這使得它們不適合高風險的決策過程，特別是在以下領域：

- **醫療診斷**：雖然生成式AI可以協助收集信息，但它不應該成為醫療診斷或治療計劃的唯一依據。
- **法律判決**：法律和先例的細微解釋需要人類專業知識，生成式AI無法可靠地複製這一點。
- **金融投資**：雖然生成式AI可以分析趨勢，但僅基於AI生成的建議做出重大財務決策會帶來巨大風險。

**為什麼會不足**：生成式AI缺乏對現實世界的理解、問責能力，以及在這些高風險情境中至關重要的考慮倫理影響的能力。

## 2. 需要情感智能的任務

雖然生成式AI可以在某種程度上模擬同理心，但它從根本上缺乏真正的情感智能。這種限制在以下方面變得明顯：

- **哀傷輔導**：哀傷輔導的細微、深刻個人性質需要人類的同理心和經驗。
- **危機情況下的領導**：在危機期間有效的領導通常需要讀懂細微的情感線索，並根據多年的人類經驗做出直覺性決策。
- **衝突解決**：解決人際或部門間衝突需要情感理解和細微的溝通，這是生成式AI無法提供的。

**為什麼會不足**：生成式AI無法真正理解或回應情感，限制了它在情感智能至關重要的情境中的效果。

## 3. 需要原創性的創意任務

雖然生成式AI可以生成創意內容，但它基本上是重新組合和推斷現有數據。這導致以下方面的限制：

- **突破性科學理論**：真正新穎的科學理論通常需要直覺的飛躍和跨學科的洞見，而生成式AI模型並不是為此設計的。
- **革命性藝術運動**：雖然生成式AI可以模仿現有風格，但發起全新的藝術運動需要AI所缺乏的文化理解和意圖性水平。
- **顛覆性商業模式**：創造從根本上重塑行業的商業模式通常需要超越現有數據模式識別的洞見。

**為什麼會不足**：生成式AI受限於其訓練數據，缺乏創造真正超越現有範式的原創想法的能力。

## 4. 需要物理互動或感官體驗的任務

生成式AI在數字領域運作，缺乏物理實體，這限制了它在以下方面的應用：

- **工藝和物理技能**：像木工、手術或演奏樂器等任務需要物理反饋和精細的運動技能。
- **實體產品的質量控制**：評估實體商品的質量通常需要感官輸入（觸摸、嗅覺、味覺），這是生成式AI無法複製的。
- **緊急響應**：急救人員需要根據生成式AI無法感知的物理環境線索做出瞬間決策。

**為什麼會不足**：缺乏物理實體和感官體驗限制了生成式AI在需要與物理世界互動的任務中的效果。

## 5. 實時動態決策

雖然生成式AI可以快速處理信息，但它在高度動態的環境中進行實時決策時遇到困難：

- **運動教練**：在比賽中做出瞬間的戰術決策需要一定水平的實時分析和直覺，這是當前生成式AI模型無法匹敵的。
- **軍事戰術**：戰場決策需要對快速變化的條件做出即時反應，這超出了預定場景的範圍。
- **現場活動管理**：管理現場活動中的意外情況需要快速思考和適應能力，這是生成式AI目前所缺乏的。

**為什麼會不足**：生成式AI模型雖然快速，但並非為這些場景所需的即時、適應性決策而設計。

## 6. 需要解釋推理的任務

在許多專業和監管環境中，提供答案或決策是不夠的 - 還必須解釋背後的推理：

- **監管合規**：許多行業需要清晰、可審核的決策過程，而當前的生成式AI模型難以提供這一點。
- **學術研究**：同行評審過程需要對方法論和推理進行清晰解釋，這是生成式AI通常無法以令人滿意的方式提供的。
- **法律論證**：建立法律論點需要一個可以被仔細審查和辯論的清晰推理鏈，這超出了生成式AI目前的能力。

**為什麼會不足**：許多生成式AI模型的"黑箱"性質使得為其輸出提供清晰、逐步的解釋變得困難。

## 執行摘要

- **CEO**：了解生成式AI是一個強大的工具，但不是萬能的。在高風險決策和創意領導方面投資人類專業知識。
- **COO**：在生成式AI擅長的領域實施它，但對於複雜、細微的流程，特別是涉及實體產品或服務的流程，保持人類監督。
- **CPO**：利用生成式AI來增強產品功能，但依靠人類洞察力進行突破性創新和需要深度同理心的用戶體驗設計。
- **CTO**：開發一種混合方法，結合生成式AI的優勢和傳統方法，特別是對於關鍵任務系統和那些需要清晰審計軌跡的系統。

{{< hint warning >}}

## 信息框：AI寒冬及其對生成式AI期望的教訓

AI的歷史曾經歷過幾次大興奮後接著失望和資金減少的時期，被稱為"AI寒冬"。最著名的發生在1970年代和1980年代末，當時人類般AI的承諾未能實現。

{{< /hint >}}

關鍵教訓：
1. 避免過度炒作能力：對生成式AI能做和不能做的事情要現實。
2. 專注於具體、可實現的應用，而不是一般的人類般智能。
3. 保持平衡的投資策略，不要過度依賴單一技術。
4. 根據現實世界的結果持續重新評估和調整期望。

通過理解這些歷史循環，組織可以更好地駕馭當前的生成式AI革命，保持熱情的同時設定現實的期望，並為潛在的挑戰做好準備。